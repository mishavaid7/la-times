{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Classifier\n",
    "\n",
    "Let's apply the classifier to the data we tried to manaully code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('assaults_downgraded_train.csv', index_col=0)\n",
    "X_test_with_answers = pd.read_csv('assaults_downgraded_test_with_answers.csv', index_col=0)\n",
    "X_test = pd.read_csv('assaults_downgraded_test.csv', index_col=0).drop(columns='downgraded').rename(columns={'serious': 'serious_you'})\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize & Classify\n",
    "\n",
    "Vectorize and classify in one big cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Define stemmer function\n",
    "stemmer = SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc:(stemmer.stem(word) for word in analyzer(doc))\n",
    "    \n",
    "# vectorize from training set    \n",
    "vectorizer = StemmedTfidfVectorizer(min_df=15, max_df=0.5)\n",
    "X = vectorizer.fit_transform(X_train.DO_NARRATIVE)\n",
    "\n",
    "# classify\n",
    "y = X_train.serious\n",
    "clf = LinearSVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# get scores - cross validate\n",
    "scores = cross_validate(clf, X, y, cv=10,\n",
    "                        scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "\n",
    "# here are some other types of scores\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "scores_df = pd.DataFrame(scores)\n",
    "display(scores_df.round(2))\n",
    "pd.DataFrame(scores)[\n",
    "    ['fit_time', 'score_time', 'test_accuracy','test_precision','test_recall','test_f1']]\\\n",
    "    .mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "No matter what the terms are that point to a report being filed as Part I or Part II, at the end of the day we're interested in seeing **how good is our model as making predictions?** To test it out, we'll need to perform some predictions on content we know the answer to. Let's start by seeing how it does on some sample sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectors = vectorizer.transform(X_test.DO_NARRATIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_vectors)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case `1` means that yes, it was a serious assault. Let's try a few more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that offenses that include weapons tend to be predicted as serious offenses, while ones involving punching or other direct physical contact are classified as simple assault.\n",
    "\n",
    "Instead of just looking at which category a report was put in, we can also look at **the score the classifier used for the prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_score = clf.decision_function(X_test_vectors)\n",
    "prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_with_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = X_test.merge(X_test_with_answers[['serious', 'downgraded']], left_index=True, right_index=True)\n",
    "compare_df['serious_clf'] = predictions\n",
    "compare_df['serious_clf_pct'] = prediction_score.round(2)\n",
    "compare_df = compare_df.sort_values(by='serious_clf_pct', ascending=True)\n",
    "compare_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "What did you get wrong? What did the machine get wrong?\n",
    "\n",
    "- What are precision errors?\n",
    "- What are recall errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter compare_df in the cells below...or save it to a CSV and open it up to answer the discussion questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.to_csv('comapre_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
